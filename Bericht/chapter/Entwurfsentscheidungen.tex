\chapter{Entwurfsentscheidungen }
\label{ch:entwurf}

\section{Programmiersprache}
Für die Wahl der Programmiersprache haben wir zunächst die Vorkenntnisse aller Gruppenmitglieder in verschiedenen erlernten Sprachen abgeschätzt und betrachtet welche Sprachen einen einfachen Einstieg in das Thema Maschine Learning erlauben. Deshalb viel unsere Wahl trotz geringerer Geschwindigkeit im Vergleich zu C++ auf Python, da ohne viel Vorwissen schnell ein erster funktionierender Prototyp erstellt werden kann und wir zudem unserer Kenntnisse in dieser Sprache vertiefen können.

Für Python gibt es eine Vielzahl geeigneter Entwicklungsumgebungen wie Eclipse oder Visual Studio, die Wahl fiel jedoch auf die kostenlose Variante von PyCharm, mit der alle Gruppenmitglieder vertraut waren.

\section{Setup}
Mit dem Ansatz im Verlauf des Projektes Maschine Learning zu verwenden, wurde recht schnell deutlich wie wichtig eine gute Hardware Ausrüstung ist, um gute Performance beim Training des Models und bei der Detektion zu erreichen. Während die Umsetzung auch ausschließlich mit CPU möglich ist, besticht der Einsatz von GPU mit deutlicher Geschwindigkeit. Um diesen Vorteil zu nutzen, haben wir uns entschlossen für das Training mit dem kostenlosen Cloud-Service von Google Colaboratory in Verbindung mit Google Drive zu arbeiten, der ebenfalls kostenlos GPU Nutzung ermöglicht. Dabei stehen uns 25 GB Ram und je nach Zuweisung eine Tesla T4 GPU mit ca.8 GB oder eine Tesla K80 GPU mit ca. 12 GB zur Verfügung, was einen 25-fachen Geschwindigkeitsvorteil von GPU gegenüber CPU darstellt. Passend zur Wahl der Programmiersprache arbeitet Google Colab mit Jupyter Notebooks und hat bereits die meisten Bibliotheken installiert, wobei fehlende mit Kommandozeilen Befehlen noch hinzugefügt werden können. 

\section{Versionsverwaltung}
Um Änderungen an Dateien und Quellcode zu erfassen und sinnvoll zu strukturieren, bietet sich aufgrund von Zusammenarbeit mehrerer Gruppenmitglieder der Einsatz einer Versionsverwaltung an. Durch Organisation mit Zeitstempeln und Benutzerkennungen kann gemeinsam an Dateien gearbeitet, Änderungen nachvollzogen, Dateien wiederhergestellt und Zugriffe koordiniert werden. Die Wahl, mit welcher Versionsverwaltung das Projekt umgesetzt werden sollte, fiel auf Git als verteiltes System, welches wir in Form von Github nutzen. Dies hat den Grund, dass Git von der genutzten Entwicklungsumgebung PyCharm unterstützt wird und alle Mitglieder unserer Gruppe bereits Github durch vorherige Projekte vertraut waren, sodass relativ wenig Einarbeitungszeit erforderlich war. Die Einbindung in Google Colab ist mit Github ebenfalls möglich, indem das jeweilige Projekt geclont wird, was wir für die Datenbank und Maschine Learning benötigten.
\todo[inline]{kürzen}
\section{Toolselection}
\todo[inline]{Abschnitt unvollständig}
\paragraph{Pandas}$~$\\
Zum lesen, sortieren und aufteilen der Datenbank haben wir die Bibliothek Pandas verwendet, die effizient in der Lage ist diese Daten zu manipulieren, zu filtern und mit fehlenden Werten umzugehen.
\paragraph{Opencv}$~$\\
Das bekannteste Computer Vision Framework Opencv besticht mit seiner Vielzahl an Algorithmen, deren Schnelligkeit durch das C++ Backend und Benutzerfreundlichkeit durch den Python Wrapper besticht. Zum Einsatz kommt OpenCv sowohl bei der Extraktion von Frames, beim Filtern als auch durch die Zeichenfunktionen. Da der Fokus auf Maschine Learning liegt, wurden wenige Verfahren der klassischen Computer Vision dieser Bibliothek verwendet.
\paragraph{Numpy}$~$\\
Für wissenschaftliche Berechnungen kam Numpy bei großen Bilddatenmengen, bei Vektorrechnungen und dem Versuch mit Ausgleichskurven zu arbeiten zum Einsatz.
\paragraph{Scipy}$~$\\
\paragraph{tensorflow}$~$\\
\paragraph{keras}$~$\\
\paragraph{PyQt} $~$\\
Für die Gestaltung der grafischen Nutzeroberfläche haben wir uns entschieden PyQt5 einzusetzen, da uns diese Bibliothek bereits aus der Programmiersprache C++ in ähnlicher Form bekannt war. Zudem besticht diese im Vergleich zu Alternativen wie TKinter durch den Ansatz GUI vom Backend zu trennen und die Möglichkeit ein modernes Design zu erstellen.

	
\section{Maschine Learning}
Vergleich und Auswahl
\todo[inline]{Vergleich fehlen}
\paragraph{Yolo}
\paragraph{ImageAI}
\paragraph{Mask rcnn}
Mask RCNN \footnote{\href{https://github.com/matterport/Mask_RCNN}{Mask RCNN}}

\section{Mask RCNN}
Wir haben uns aus folgenden Gründen für Mask-RCNN entschieden:
\begin{itemize}
	\item \textbf{zuverlässige Detektion:}

		Auch unter schwierigen Bedingungen verspricht M-RCNN eine präzise, zuverlässige Detektion.
		Nach der zweiten Iteration des Praktikums sahen wir, dass die anderen Gruppen mit YOLO deutlich mehr Probleme hatten als wir mit M-RCNN. Auch wenn die Performance an YOLO nie herankam, war die Qualität der Klassifikation und Regionenbestimmung immer sehr hoch.
	\item \textbf{leichter Einstieg:}

		Auch wenn es subjektiv (noch) nicht so weit verbreitet ist wie YOLO fanden sich zwar wenige - dafür aber sehr gute Quellen zum Einstieg inklusive Tutorials und jupyter notebooks direkt aus dem git repository der Entwickler.
	\item \textbf{Segmentierung:}

		M-RCNN kann Segmentierungsmasken berechnen.
		Auch wenn wir die Masken letztendlich noch nicht verwendet haben, erschien es uns als sehr vorteilhaft, diesen Trumpf in der Hinterhand zu haben.
	\item \textbf{Interesse:}

		Beim Stöbern haben wir gesehen, dass M-RCNN ein relativ neues Verfahren ist.
		Da wir wussten, dass die meisten anderen Gruppen sich für YOLO entscheiden würden sind wir nicht zuletzt auch deshalb den Weg mit M-RCNN gegangen.
		Wir wollten sehen, wie es sich verhält im Vergleich zu YOLO. Sinn und Ziel des Praktikums ist es ja auch gewesen, Neues auszuprobieren und zu experimentieren/erforschen und aktuelle Verfahren und state-of-the-art-Techniken kennenzulernen.

\end{itemize}
