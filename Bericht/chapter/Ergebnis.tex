\chapter{Ergebnisauswertung}
\label{ch:ergebnis}

Qualitative Auswertung:

•	Diskussion Zielerreichung

•	Untersuchung der Bedienung


•	Empfehlung noch nicht implementierter Funktionen

\vspace{1cm}

Bugs:

•	Prototyp

•	fehlender Praxistest

•	bisher nur Grundfunktionen

\vspace{1cm}

Verbesserungen:

•	Performance für Live Übertragung

•	Model Training erweitern

•	Festlegung welchem Reiterpaar situationsbedingt gefolgt werden soll

•	Bildentzerrung?


\vspace{1cm}
Zusammenfassung der Beobachtungen
	
	
•	Einstufung der Fehler und ihre Wichtigkeit

•	Fehlertoleranz

•	Ursachenanalyse
	
•	Verbesserungsvorschläge
	
•	Interssenskonflike(Performance und Zeitaufwand)
	
•	Beurteilung der Resourcen (Zeit, Vorwissen, erworbene Kenntnisse )

•	Effektivität

•	Effizienz

•	Zufriedenstellung/Akzeptanz

•	Aufgabenangemessenheit

•	Erlernbarkeit

•	Erwartungskonformität



\section{Planung}
Die vorgegebenen Phasen aus der Aufgabenstellung dieses Projektes stellten sich als sehr hilfreich für ein sinnvolles schrittweises Vorgehen und dessen Umsetzung heraus, besonders im Hinblick auf fehlendes Vorwissen aller Gruppenmitglieder in der Thematik Maschine Learning. Während die erste Phase problemlos ablief, gestaltete sich der praktische Einstieg in Phase zwei dagegen relativ langwierig bis wir einen ersten Prototypen unseres Detektors erstellen konnten. Als Folge dessen war es uns nicht vollständig möglich das Ziel eines Reiterpaardetektors bereits in Phase 2 fertigzustellen, da dieser an einigen Stellen noch Fehler aufwies, welche jedoch direkt zu Beginn der dritten Phase behoben wurden. Ebenfalls sollte in der zweiten Phase das Labelling weiterer Daten umgesetzt werden, wobei die entsprechend vereinfachte Benutzung dieses Zieles erst mithilfe der GUI in Phase drei hinzugefügt wurde. Diese zeitlichen Verschiebungen konnten jedoch in mit effizienter Aufgabenteilung gut bewältigt werden und stellten kein Hindernis für die letzte Phase dar.
Durch die recht allgemeine Formulierung der Ziele in Phase drei, die einen Fokus auf robustes und flüssiges Tracking, haben wir die daraus abgeleiteten Gruppenziele in den Vordergrund gestellt. Obwohl einige Konzepte, die aus Effizienz- oder Performancegründen verworfen wurden, erprobt wurden, konnten die Projektziele eingehalten werden. 

\section{Umsetzung und Zielerreichung}
Im Folgende betrachten wir die Umsetzung der einzelnen Ziele und die Einstufung von bestehenden Fehler sowie deren Wichtigkeit



\subsection*{ Detektor}
Der erste Schritt für die autonome Kameraführung war die Erstellung eines Detektors für Reiter und Pferd sowie später auch für Reiterpaare. Diesen konnten wir erfolgreich mithilfe von Maschine Learning umsetzten, indem wir die erstellten Trainingsdaten der ersten Phase als Grundlage genutzt haben und den Detektor später um weitere Datensätze erweitert haben. Mit Wahl von Mask RCNN haben wir schon am Ende der zweiten Phase ausreichende Genauigkeit erreicht, dass wir problemlos zusätzliche Daten mit weiteren Videomaterial labeln konnten, obwohl sich die Umgebung und die Reiterpaare unterschieden. Die Schnelligkeit des Labelings konnten wir durch eine graphische Benutzeroberfläche gewährleisten, mit welcher ein Nutzer die möglichen Detekionen beurteilen kann. Trotz der erfolgten Erweiterung des Detektors ist es in jeder neuen Umgebung auch weiterhin nötig diesen weiter zu trainieren, da durchaus fehlerhafte Erkennungen auftreten können.
Das Detektieren von Reiterpaaren konnten wir simpel mithilfe der Überdeckung von Reiter und Pferd lösen. Als Folge dessen konnten wir einzelne Reiter und Pferde ausschließen, was in neuen Umgebungen robusteres Detektieren zur Folge hat.



\subsection*{ Tracker}
Um eine flüssige und robuste Verfolgung des Reiterpaares zu ermöglichen haben wir viele grundlegende Problematiken betrachtet und schrittweise gelöst. Neben der Behandlung der Bildränder haben wir auch die Problematik von Verdeckung und dem fehlerhaften oder fehlenden detektieren von mehreren und einzelnen Reitern behandelt. Mit den errechneten Bounding Boxen konnten wir die jeweiligen RoIs der einzelnen Frames bestimmen und mit der Anwendung eines Gaußfilters auch eine angenehme Videoqualität ermöglichen.
\todo[inline]{Abschnitt unvollständig}

\section{Ausblick}
Durch die zeitlichen Vorgaben konnten nicht alle Ideen und Ansätze ausprobiert werden, jedoch sehen wir in einigen Aspekten großes Potenzial zur Verbesserung und Erweiterung.

Der erstellte Detektor für Reiterpaare sollte sowohl für eine Vielzahl von Umgebungen mit anderen Reitern und Pferden trainiert werden, als auch für verschiedene Reitdisziplinen wie beispielsweise Springreiten oder Westernreiten. 
Um eine noch robustere Verfolgung eines Reiterpaares zu ermöglichen sind weitere Sonderfälle, wie das Kreuzen und längeres Verdecken von Reitern zu beachten. Ebenfalls sind Ausnahmesituationen wie Stürze von Interesse, da in diesem Fall Reiter und Pferd nicht mehr als Paar erkannt würden.
Ein ausgiebiger Praxistest würde uns an dieser Stelle Aufschluss über nötige Erweiterungen und Problematiken geben.

Im Hinblick auf den Einsatz für Live Tracking müsste der bestehende Smart Camera Operator an einigen Stellen modifiziert werden, da im Rahmen des Projektes nur mit Aufzeichnungen gearbeitet wurde. Besonders müsste die Performance dafür deutlich erhöht werden, damit die Erkennung für ca. 25 fps erreicht werden kann. Davon ausgehend könnten dann auch Kamerabewegungen ermöglicht werden, die dem fokussierten Reiterpaar mittels Translationen und Rotationen folgt.

